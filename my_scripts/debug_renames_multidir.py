import subprocess
import os
import sys
import csv
import time
import argparse
import re
import ctypes
import shutil

# ================= é…ç½®åŒºåŸŸ =================

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
DOC_DIR = os.path.join(PROJECT_ROOT, "my_docs")

TARGET_SCAN_DIRS = [
    os.path.join(PROJECT_ROOT, "src"),
    os.path.join(PROJECT_ROOT, "tools"),
]

REFACTOR_SCRIPT_PATH = os.path.join(SCRIPT_DIR, "content_refactor_batch.py")
SOURCE_CSV_PATH = os.path.join(DOC_DIR, "occt_renaming_map.csv")
WORK_CSV_PATH = os.path.join(DOC_DIR, "occt_renaming_map_new.csv")

BAD_ROWS_LOG = os.path.join(DOC_DIR, "bad_names.txt") # è®°å½•ä¿®å¤ç»“æœ
GOOD_ROWS_LOG = os.path.join(DOC_DIR, "good_renames.txt")

SLN_PATH = os.path.normpath(os.path.join(PROJECT_ROOT, "..", "OCCTBUILD", "OCCT.sln"))

CMD_BUILD = ["msbuild", SLN_PATH, "/t:Build", "/p:Configuration=Release", "/maxCpuCount", "/p:StopOnFirstFailure=true"]
CMD_CLEAN = ["msbuild", SLN_PATH, "/t:Clean", "/p:Configuration=Release", "/maxCpuCount"]

CHUNK_SIZE = 50

# ========================================================

def disable_quick_edit():
    if os.name != 'nt': return
    try:
        kernel32 = ctypes.windll.kernel32
        hInput = kernel32.GetStdHandle(-10)
        mode = ctypes.c_ulong()
        if not kernel32.GetConsoleMode(hInput, ctypes.byref(mode)): return
        new_mode = mode.value & ~0x0040
        kernel32.SetConsoleMode(hInput, new_mode)
    except: pass

def init_work_csv():
    if not os.path.exists(WORK_CSV_PATH):
        shutil.copy2(SOURCE_CSV_PATH, WORK_CSV_PATH)

def count_csv_rows(filepath):
    with open(filepath, 'r', encoding='utf-8-sig') as f:
        reader = csv.reader(f)
        try: next(reader)
        except StopIteration: return 0
        return sum(1 for row in reader)

def kill_process_tree(pid):
    try: subprocess.run(["taskkill", "/F", "/T", "/PID", str(pid)], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=False)
    except: pass

def nuke_build_processes():
    targets = ["cl.exe", "link.exe", "vctip.exe", "mspdbsrv.exe", "msbuild.exe"]
    for proc in targets:
        subprocess.run(["taskkill", "/F", "/IM", proc], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=False)
    time.sleep(0.5)

def run_command(cmd, desc, stop_on_error=False):
    print(f"  [æ‰§è¡Œ] {desc}...", end="", flush=True)
    start_time = time.time()
    cmd_str = list(map(str, cmd))
    process = None
    captured_error_line = None
    error_type = "NONE"
    
    try:
        process = subprocess.Popen(
            cmd_str, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            shell=False, text=True, encoding='utf-8', errors='replace'
        )
    except Exception as e:
        print(f"\n  âŒ å¯åŠ¨å¤±è´¥: {e}")
        return False, None, "FATAL"

    error_detected = False
    
    while True:
        line = process.stdout.readline()
        if line:
            if stop_on_error:
                l_low = line.lower()
                if ": error" in l_low or "error c" in l_low or "fatal error" in l_low:
                    error_detected = True
                    captured_error_line = line.strip()
                    if "lnk" in l_low: error_type = "LINKER"
                    elif "fatal" in l_low: error_type = "FATAL"
                    else: error_type = "COMPILER"
                    print(f"\n\n{'!'*10} æ•è· {error_type} {'!'*10}\n{captured_error_line}\n{'!'*35}")
                    kill_process_tree(process.pid)
                    break
        elif process.poll() is not None:
            break
        else:
            time.sleep(0.05)

    if process and process.poll() is None:
        kill_process_tree(process.pid)
        process.wait()

    duration = time.time() - start_time
    success = (not error_detected) and (process.returncode == 0)
    
    if success: print(f" -> âœ… ({duration:.1f}s)")
    else: print(f" -> ğŸ›‘ ({duration:.1f}s)")
    
    return success, captured_error_line, error_type

def run_clean():
    print("\n  [æ¸…ç†] æ‰§è¡Œ Clean...")
    nuke_build_processes()
    subprocess.run(list(map(str, CMD_CLEAN)), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=False)

def reset_all_targets():
    for target in TARGET_SCAN_DIRS:
        if not os.path.exists(target): continue
        for i in range(3):
            try:
                subprocess.run(["git", "checkout", "HEAD", "--", target], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                subprocess.run(["git", "clean", "-fd", target], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                break 
            except:
                if i==2: nuke_build_processes()
                time.sleep(1)

def apply_refactoring_to_all(start, end):
    for target in TARGET_SCAN_DIRS:
        if not os.path.exists(target): continue
        cmd = [
            "python", REFACTOR_SCRIPT_PATH, target, WORK_CSV_PATH,
            "--start_row", str(start), "--end_row", str(end), "--run"
        ]
        success, _, _ = run_command(cmd, f"æ›¿æ¢ '{os.path.basename(target)}'", stop_on_error=False)
        if not success: return False
    return True

# --- æ™ºèƒ½è¾…åŠ©å‡½æ•° ---

def get_all_current_names():
    names = set()
    with open(WORK_CSV_PATH, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for row in reader:
            n = row.get('Suggested_New_Name', '').strip()
            if n: names.add(n)
    return names

def generate_fix_candidates(original_name, current_new_name, used_names):
    candidates = []
    if '_' not in original_name:
        return [original_name] if original_name != current_new_name else []

    parts = original_name.split('_', 1)
    prefix = parts[0]
    suffix = parts[1]
    upper_count = sum(1 for c in suffix if c.isupper())
    
    cand_join = prefix + suffix
    
    base_cand_drop = suffix
    cand_drop = base_cand_drop
    counter = 1
    while cand_drop in used_names and cand_drop != current_new_name:
        cand_drop = f"{base_cand_drop}{counter}"
        counter += 1
    
    if upper_count <= 1:
        candidates.append(cand_join)
        candidates.append(cand_drop)
    else:
        candidates.append(cand_drop)
        candidates.append(cand_join)
    
    candidates.append(original_name)
    
    final_candidates = []
    for c in candidates:
        if c != current_new_name and c not in final_candidates:
            final_candidates.append(c)
    return final_candidates

def update_csv_row(row_num, new_name):
    rows = []
    header = []
    with open(WORK_CSV_PATH, 'r', encoding='utf-8-sig', newline='') as f:
        reader = csv.reader(f)
        header = next(reader)
        rows = list(reader)
    idx = row_num - 1
    if 0 <= idx < len(rows):
        col_idx = header.index('Suggested_New_Name')
        rows[idx][col_idx] = new_name
        with open(WORK_CSV_PATH, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(header)
            writer.writerows(rows)

def get_row_info(row_num):
    with open(WORK_CSV_PATH, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader, start=1):
            if i == row_num:
                return row['Original_Class_Name'], row['Suggested_New_Name']
    return None, None

def log_fix(row_num, old_name, fix_name, original_name):
    msg = f"Row {row_num}: FIX [{old_name}] -> [{fix_name}] (Orig: {original_name})"
    print(f"\nâœ… {msg}")
    with open(CHANGE_LOG, "a", encoding="utf-8") as f:
        f.write(msg + "\n")

def attempt_auto_fix(row_num):
    print(f"\nğŸ”§ [è‡ªåŠ¨ä¿®å¤] æ­£åœ¨å°è¯•ä¿®å¤ç¬¬ {row_num} è¡Œ...")
    orig_name, curr_new_name = get_row_info(row_num)
    if not orig_name: return False

    used_names = get_all_current_names()
    candidates = generate_fix_candidates(orig_name, curr_new_name, used_names)
    
    print(f"  åŸå§‹: {orig_name} | å½“å‰: {curr_new_name}")
    print(f"  æ–¹æ¡ˆ: {candidates}")

    for cand in candidates:
        print(f"  ğŸ‘‰ å°è¯•æ–¹æ¡ˆ: {cand} ...")
        update_csv_row(row_num, cand)
        reset_all_targets() # æ¸…ç†æ—§ä»£ç 
        if not apply_refactoring_to_all(row_num, row_num): continue
        success, _, _ = run_command(CMD_BUILD, "éªŒè¯ä¿®å¤", stop_on_error=True)
        if success:
            log_fix(row_num, curr_new_name, cand, orig_name)
            reset_all_targets()
            return True
        else:
            print(f"     âŒ æ–¹æ¡ˆå¤±è´¥ã€‚")
            reset_all_targets()

    # ä¿®å¤å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹åï¼ˆæ”¾å¼ƒæ²»ç–—ï¼‰
    update_csv_row(row_num, orig_name)
    with open(CHANGE_LOG, "a", encoding="utf-8") as f:
        f.write(f"Row {row_num}: FAILED FIX. Reverted to {orig_name}\n")
    return False

# --- æ™ºèƒ½å®šä½ç›¸å…³ ---

def get_csv_range_map(start, end):
    name_to_row = {}
    try:
        with open(WORK_CSV_PATH, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for i, row in enumerate(reader, start=1):
                if i < start: continue
                if i > end: break
                new_name = row.get('Suggested_New_Name', '').strip()
                if new_name: name_to_row[new_name] = i
    except: pass
    return name_to_row

def extract_word_at_index(text, index):
    if index >= len(text): index = len(text) - 1
    if index < 0: return ""
    if not re.match(r'\w', text[index]):
        while index > 0 and not re.match(r'\w', text[index]): index -= 1
    if not re.match(r'\w', text[index]): return ""
    start = index
    while start > 0 and re.match(r'\w', text[start-1]): start -= 1
    end = index
    while end < len(text)-1 and re.match(r'\w', text[end+1]): end += 1
    return text[start : end+1]

def get_smart_suspects(error_line, start, end):
    if not error_line: return []
    pattern = r"(?:^\d+>)?\s*(.*)\((\d+),(\d+)\)\s*:\s*error"
    match = re.search(pattern, error_line)
    if not match: return []

    file_path = match.group(1).strip()
    line_num = int(match.group(2))
    col_num = int(match.group(3))
    
    if not os.path.exists(file_path): return []

    line_content = ""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
            if line_num <= len(lines):
                line_content = lines[line_num - 1]
    except: return []

    if not line_content: return []

    chunk_map = get_csv_range_map(start, end)
    
    token_tier1 = extract_word_at_index(line_content, col_num - 1)
    if token_tier1 and token_tier1 in chunk_map:
        print(f"  [æ™ºèƒ½åˆ†æ] ğŸ¯ å‘½ä¸­ä½ç½®: '{token_tier1}' (Row {chunk_map[token_tier1]})")
        return [chunk_map[token_tier1]]

    print(f"  [æ™ºèƒ½åˆ†æ] ç²¾ç¡®æœªå‘½ä¸­ (æå–: '{token_tier1}')ï¼Œè½¬å…¨è¡Œæ‰«æ...")
    tokens_in_line = set(re.findall(r"\w+", line_content))
    suspects = []
    for token in tokens_in_line:
        if token in chunk_map:
            suspects.append(chunk_map[token])
    
    suspects.sort()
    if suspects:
        print(f"  [æ™ºèƒ½åˆ†æ] è¡Œå†…å«Œç–‘äºº: {suspects}")
    
    return suspects

def log_good_range(start, end):
    if start <= end:
        print(f"  >>> âœ… èŒƒå›´é€šè¿‡: {start}-{end}")
        with open(GOOD_ROWS_LOG, "a", encoding="utf-8") as f:
            f.write(f"{start}-{end}\n")

# --- ä¸»é€»è¾‘ ---

def check_range(start, end, last_build_success=True):
    if start > end: return

    print(f"\n--- æ£€æŸ¥èŒƒå›´: {start} åˆ° {end} (å…± {end - start + 1} è¡Œ) ---")
    
    if not apply_refactoring_to_all(start, end):
        reset_all_targets()
        return

    success, error_line, error_type = run_command(CMD_BUILD, "ç¼–è¯‘æ£€æŸ¥", stop_on_error=True)

    if not success and error_type in ["LINKER", "FATAL"]:
        if not last_build_success:
            print(f"  [ç­–ç•¥] é‡åˆ° {error_type} ä¸”å¤„äºé‡è¯•é˜¶æ®µ -> æ¸…ç†å¹¶é‡è¯•...")
            run_clean()
            success, error_line, error_type = run_command(CMD_BUILD, "é‡è¯•ç¼–è¯‘", stop_on_error=True)
        else:
            print(f"  [ç­–ç•¥] é‡åˆ° {error_type} ä½†ä¸Šæ¬¡æˆåŠŸ -> åˆ¤å®šä¸ºä»£ç é”™è¯¯")

    # === å…³é”®ï¼šå…ˆåšæ™ºèƒ½å®šä½ï¼Œå†é‡ç½®ä»£ç ï¼===
    suspect_rows = []
    if not success and start != end:
        suspect_rows = get_smart_suspects(error_line, start, end)
    # ========================================

    reset_all_targets()

    if success:
        log_good_range(start, end)
        return

    # === å¤±è´¥å¤„ç† ===
    
    # 1. èŒƒå›´ç¼©å°åˆ°å•è¡Œ -> ç›´æ¥ä¿®å¤
    if start == end:
        print(f"âš ï¸  é”å®šåè¡Œ: {start}")
        attempt_auto_fix(start)
        return

    # 2. æ™ºèƒ½å®šä½å‘½ä¸­ -> å°è¯•ä¿®å¤å«Œç–‘äºº
    if suspect_rows:
        found_real_culprit = False
        for s_row in suspect_rows:
            print(f"  [éªŒè¯] æ­£åœ¨æ’æŸ¥å«Œç–‘è¡Œ: {s_row} ...")
            # è¿™é‡Œè°ƒç”¨ attempt_auto_fixï¼Œå®ƒå†…éƒ¨ä¼šè¿›è¡Œ æ›¿æ¢->ç¼–è¯‘->å›æ»š
            # å¦‚æœä¿®å¤æˆåŠŸï¼Œè¿”å› True
            if attempt_auto_fix(s_row):
                found_real_culprit = True
                # ä¿®å¤äº†ä¸€ä¸ªï¼Œå¯èƒ½è¿˜æœ‰åˆ«çš„ï¼Œä½†ä¸ºäº†å®‰å…¨ï¼Œæˆ‘ä»¬é€’å½’æ£€æŸ¥
                # æ³¨æ„ï¼šå·²ç»ä¿®å¤çš„è¡Œï¼Œåœ¨ CSV é‡Œå˜æˆäº†æ–°åå­—ï¼Œåç»­ check_range ä¼šä½¿ç”¨æ–°åå­—å†æ¬¡éªŒè¯ï¼Œç†åº”é€šè¿‡
                if s_row > start: check_range(start, s_row - 1, last_build_success=False)
                if s_row < end: check_range(s_row + 1, end, last_build_success=False)
                return

        if not found_real_culprit:
            print("  [æ™ºèƒ½åˆ†æ] æ‰€æœ‰å«Œç–‘è¡Œä¿®å¤å°è¯•å‡æ— æ•ˆ/æ— éœ€ä¿®å¤ã€‚å›é€€äºŒåˆ†æ³•ã€‚")

    # 3. å›é€€äºŒåˆ†æ³•
    mid = (start + end) // 2
    check_range(start, mid, last_build_success=False)
    check_range(mid + 1, end, last_build_success=False)

def main():
    disable_quick_edit()
    parser = argparse.ArgumentParser()
    parser.add_argument("--start_row", type=int, default=1)
    args = parser.parse_args()

    if not os.path.exists(SOURCE_CSV_PATH): return
    init_work_csv()
    
    log_mode = "w" if args.start_row == 1 else "a"
    try:
        with open(CHANGE_LOG, log_mode, encoding="utf-8") as f:
            if log_mode == "w": f.write(f"Fix Log\n")
        with open(GOOD_ROWS_LOG, log_mode, encoding="utf-8") as f:
            if log_mode == "w": f.write(f"Good Ranges Log\n")
    except: pass

    total_rows = count_csv_rows(WORK_CSV_PATH)
    current = args.start_row
    
    print(f"æ€»è¡Œæ•°: {total_rows} | èµ·å§‹: {current} | æ­¥é•¿: {CHUNK_SIZE}")
    
    while current <= total_rows:
        end = current + CHUNK_SIZE - 1
        if end > total_rows: end = total_rows
        check_range(current, end, last_build_success=True)
        current = end + 1

    print("\næ‰«æå®Œæˆï¼")

if __name__ == "__main__":
    main()